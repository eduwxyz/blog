---
date: '2025-04-26T10:27:14-03:00'
draft: false
title: 'Entendendo FastAPI, async/sync e a verdadeira escalabilidade de APIs'
tags: [python,fastapi, cloud run]
---

# FastAPI no Cloud Run: Entendendo de Verdade o que Roda por Tr√°s

Quando come√ßamos a desenvolver APIs modernas, √© f√°cil cair na armadilha de acreditar que basta usar ferramentas "r√°pidas" para termos aplica√ß√µes escal√°veis.

**FastAPI no Cloud Run? Pronto! Sucesso garantido.**

Mas ser√° que √© s√≥ isso mesmo?  
Ser√° que sabemos o que realmente acontece entre o servidor que recebe as requisi√ß√µes e a forma como o Python executa nosso c√≥digo?

Neste artigo, quero fazer um passeio pelas camadas envolvidas nesse processo:  
**Cloud Run ‚Üí Uvicorn ‚Üí FastAPI ‚Üí Event Loop e ThreadPool.**

---

## ‚òÅÔ∏è Cloud Run: Infraestrutura Serverless para Suas APIs


O [Cloud Run](https://cloud.google.com/run) √© um servi√ßo da Google que executa containers de maneira autom√°tica e escal√°vel.  
Voc√™ sobe um container e ele cuida de praticamente tudo:

- Gerenciamento de infraestrutura  
- Balanceamento de carga  
- Escalonamento autom√°tico (de zero at√© milhares de inst√¢ncias)

![Descri√ß√£o da Imagem](image.png)

**A promessa √© linda:** seu c√≥digo escala sem voc√™ se preocupar com servidores.

Mas tem um detalhe importante:  
**O Cloud Run escala inst√¢ncias ‚Äî n√£o conex√µes.**

Ou seja, cada inst√¢ncia precisa ser bem otimizada para lidar com m√∫ltiplas requisi√ß√µes ao mesmo tempo.  
N√£o adianta rodar c√≥digo ineficiente esperando que o Cloud Run "milagre" a performance.

---

### Como Funcionam as Inst√¢ncias no Cloud Run?

Quando voc√™ sobe seu servi√ßo no Cloud Run, ele fica "adormecido", esperando a primeira chamada.

- Chegou uma requisi√ß√£o? O Cloud Run ativa seu container.
- Chegaram v√°rias requisi√ß√µes? Ele **automaticamente** cria mais inst√¢ncias para atender ao volume.

Cada inst√¢ncia funciona como uma mini-f√°brica do seu c√≥digo.  
Se o movimento aumenta, mais f√°bricas entram em opera√ß√£o. Se o movimento cai, elas s√£o desligadas para economizar recursos (e dinheiro).

**Mas aten√ß√£o:**
- Cada inst√¢ncia tem capacidade limitada de processamento.
- Cada inst√¢ncia pode lidar com v√°rias requisi√ß√µes ao mesmo tempo (conhecido como *concurrency*).
- O uso de CPU, mem√≥ria e tempo influencia diretamente no custo.

Se seu c√≥digo √© r√°pido e eficiente, uma √∫nica inst√¢ncia pode dar conta de muitas requisi√ß√µes.  
Se for lento ou bloqueante, voc√™ precisar√° de mais inst√¢ncias (e vai pagar mais por isso).

---

### Entendendo a Concurrency


![Descri√ß√£o da Imagem](image1.png)

A *concurrency* define quantas requisi√ß√µes uma inst√¢ncia consegue atender simultaneamente.  
Por padr√£o, o Cloud Run permite at√© **80 requisi√ß√µes simult√¢neas por inst√¢ncia**, mas isso √© configur√°vel.

**Importante:**
- Se sua aplica√ß√£o **n√£o** √© *thread-safe* ou lida mal com concorr√™ncia, o Google recomenda limitar a *concurrency* para **1**.
- Se sua aplica√ß√£o lida bem com m√∫ltiplas requisi√ß√µes paralelas, voc√™ pode (e deve) aumentar essa configura√ß√£o para reduzir custos e melhorar a performance.

---

## ü§ù Conectando Infraestrutura e C√≥digo

Agora que entendemos como o Cloud Run gerencia inst√¢ncias, vamos olhar para o outro lado:  
**Como nosso c√≥digo Python pode aproveitar melhor essa infraestrutura?**

---

## üîÑ Sync, Async e o Event Loop no Python


![Descri√ß√£o da Imagem](image2.png)



### O Modelo Tradicional (S√≠ncrono)

Em programa√ß√£o s√≠ncrona, cada opera√ß√£o bloqueia a thread at√© terminar:

```python
def buscar_usuario(id: int):
    resultado = banco.executar_query(f"SELECT * FROM usuarios WHERE id = {id}")
    return resultado

def processar_pedido():
    usuario = buscar_usuario(1)
    produtos = buscar_produtos(usuario.id)
    return criar_pedido(produtos)
```

Problemas:
* Cada requisi√ß√£o bloqueia a thread
* Recursos ficam ociosos durante esperas
* Escalabilidade severamente limitada


### O Modelo Ass√≠ncrono e o Event Loop
Com async/await, o Python permite liberar a thread enquanto espera uma opera√ß√£o I/O terminar:

```python
async def buscar_usuario(id: int):
    resultado = await banco.executar_query(f"SELECT * FROM usuarios WHERE id = {id}")
    return resultado

async def processar_pedido():
    usuario = await buscar_usuario(1)
    produtos = await buscar_produtos(usuario.id)
    return await criar_pedido(produtos)
```

O Event Loop √© o maestro que coordena essas opera√ß√µes:
* Mant√©m uma fila de tarefas a serem executadas
* Quando uma tarefa aguarda I/O, ele passa para a pr√≥xima
* Assim que o I/O termina, ele retoma a tarefa original

### ‚ö° FastAPI: Concorr√™ncia Sem Dor

O FastAPI √© constru√≠do sobre o Starlette, que por sua vez √© um framework ASGI ‚Äî o que o torna nativamente ass√≠ncrono.

Ele permite que voc√™ defina endpoints:
* S√≠ncronos (`def`)
* Ass√≠ncronos (`async def`)

Mas com um diferencial importante:
> Mesmo endpoints def s√£o executados de forma n√£o bloqueante gra√ßas a um ThreadPool interno gerenciado pelo Starlette/Uvicorn.

### Como Funciona?

* Endpoints `async` def: aproveitam o event loop e rodam em corrotinas.
* Endpoints `def`: s√£o executados em um ThreadPoolExecutor (por padr√£o, ~40 threads por worker).

Na pr√°tica, isso significa:
* Voc√™ pode lidar com v√°rias requisi√ß√µes simult√¢neas, mesmo com endpoints s√≠ncronos.
* O servidor continua responsivo, mesmo durante chamadas bloqueantes como sleep() ou I/O s√≠ncrono.

```python
from fastapi import FastAPI
from time import sleep

app = FastAPI()

# Endpoint s√≠ncrono (executado no ThreadPool)
@app.get("/produtos")
def listar_produtos():
    sleep(1)  # Simulando opera√ß√£o bloqueante
    return {"produtos": ["Produto 1", "Produto 2"]}

# Endpoint ass√≠ncrono (executado no Event Loop)
@app.get("/usuarios")
async def listar_usuarios():
    await processar_algo()
    return {"usuarios": ["Usu√°rio 1", "Usu√°rio 2"]}
```

### Conclus√£o: Escalabilidade √© Sobre C√≥digo Inteligente

O FastAPI, combinado com o Cloud Run, oferece um ambiente poderoso para APIs modernas ‚Äî **desde que voc√™ escreva c√≥digo preparado para concorr√™ncia**.

**Resumo dos aprendizados**:
* O Cloud Run escala inst√¢ncias, mas cada inst√¢ncia precisa lidar bem com concorr√™ncia.
* O FastAPI permite endpoints `def` e `async def` ‚Äî ambos funcionam bem desde que voc√™ entenda o que est√° fazendo.
* Programa√ß√£o ass√≠ncrona n√£o √© m√°gica, mas √© fundamental para escalar APIs com I/O intensivo.
* Mesmo c√≥digo s√≠ncrono pode escalar se usado com responsabilidade (e rodando no ThreadPool certo).